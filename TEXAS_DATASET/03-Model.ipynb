{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texas Dataset Model\n",
    "- gather data \n",
    "- clean data\n",
    "- feature engineering\n",
    "- define model\n",
    "- training, testing and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import glob, os\n",
    "import my_lib as ml\n",
    "import json\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer, accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "SEED = 42\n",
    "target = \"TARGET\"\n",
    "metric = \"recall_macro\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Facility to our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(597, 10)\n",
      "(49984, 43)\n",
      "(100000, 41)\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(f\"data/df_train_sample_00_of_20.csv\", dtype=str)\n",
    "df_facility = pd.read_csv(\"data/facility.csv\", dtype = str)\n",
    "df_grading_raw = pd.read_csv(f\"data/grading.csv\", dtype=str)\n",
    "\n",
    "print(df_facility.shape)\n",
    "print(df_raw.shape)\n",
    "print(df_grading_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49984, 52)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.merge(df_raw, df_facility, on=\"THCIC_ID\", how=\"left\")\n",
    "display(df.shape)\n",
    "\n",
    "# replace empty values\n",
    "df_facility_columns = []\n",
    "for i in range(2, len(df_facility.columns) - 1):\n",
    "    col = df_facility.columns[i]\n",
    "    df[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_facility_columns.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'long', 1: 'medium', 2: 'short'}\n"
     ]
    }
   ],
   "source": [
    "if df['TARGET'].dtype!=int:\n",
    "    le_target = LabelEncoder()\n",
    "    df['TARGET']= le_target.fit_transform(df['TARGET'])\n",
    "else:\n",
    "    print(f'DF[\"TARGET\"] is already of type int.')\n",
    "    pass\n",
    "\n",
    "target_labels = {c:le_target.inverse_transform([c])[0] for c in [0,1,2]}\n",
    "print(target_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE_OF_ADMISSION: -> ['3' '1' '2' '4' '5' '9']\n",
      "SOURCE_OF_ADMISSION: -> ['4' '1' '2' '8' '5' '9' '6' 'D']\n",
      "PAT_STATE: -> ['TX' 'XX' 'ZZ']\n",
      "SEX_CODE: -> ['F' 'M' 'U']\n",
      "RACE: -> ['4' '5' '3' '2' '1']\n",
      "ETHNICITY: -> ['2' '1' '3']\n",
      "PAT_AGE: -> ['5' '4' '2' '3' '1']\n",
      "PAT_COUNTRY: -> ['US' 'MX' 'XX']\n",
      "POA_PROVIDER_INDICATOR: -> ['X' 'M' 'R']\n",
      "ILLNESS_SEVERITY: -> ['3' '2' '1' '4']\n",
      "RISK_MORTALITY: -> ['2' '1' '3' '4']\n"
     ]
    }
   ],
   "source": [
    "ml.clean_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- bucket \"PAT_STATE\" into people living in texas and people who doesnt live in texas.\n",
    "- bucket the \"ADMIT_WEEKDAY\" into weekday or weekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df_input):\n",
    "    feature = \"PAT_STATE\"\n",
    "    df_input[\"NON_TEXAS\"] = df_input[feature] != \"TX\"\n",
    "    df_input[\"FROM_TEXAS\"] = df_input[feature] == \"TX\"\n",
    "\n",
    "    feature = \"ADMIT_WEEKDAY\"\n",
    "    df_input[\"WEEK_DAY\"] = ((df_input[feature] != \"6\") & (df_input[feature] != \"7\"))\n",
    "    df_input[\"WEEK_END\"] = (df_input[feature] == \"6\") | (df_input[feature] == \"7\")\n",
    "    \n",
    "feature_engineering(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset in Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(input_df):\n",
    "    x = input_df.drop(target, axis=1)\n",
    "    y = input_df.TARGET\n",
    "\n",
    "    df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(x, y, test_size = 0.4, stratify = y, random_state = SEED)\n",
    "    \n",
    "    return df_X_train, df_X_test, df_y_train, df_y_test\n",
    "\n",
    "df_x_train, df_x_test, df_y_train, df_y_test = split_train_test(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "target_features = [\"SOURCE_OF_ADMISSION\", \"PAT_STATE\", \"SEX_CODE\", \"RACE\", \"ETHNICITY\", \"ADMIT_WEEKDAY\", \"PAT_AGE\", \"PAT_COUNTRY\", \"POA_PROVIDER_INDICATOR\", \"ILLNESS_SEVERITY\", \"RISK_MORTALITY\"]\n",
    "engineered_features = [\"NON_TEXAS\", \"FROM_TEXAS\", \"WEEK_DAY\", \"WEEK_END\"]\n",
    "\n",
    "def encode_features(df_x_train, df_x_test, target_features, engineered_features, df_facility_columns,  debug=False):\n",
    "    # create dataframes to populate\n",
    "    dfx_train_model = df_x_train.loc[:,[]]\n",
    "    dfx_test_model = df_x_test.loc[:,[]]\n",
    "\n",
    "    # encoding features using LabelBinarizer\n",
    "    for feature in target_features:\n",
    "\n",
    "        lb = LabelBinarizer()\n",
    "        lb_result = lb.fit_transform(df_x_train[feature].astype(\"str\"))\n",
    "        names = [f'{feature}_{l}' for l in lb.classes_]\n",
    "\n",
    "        for k, name in enumerate(names):\n",
    "            dfx_train_model[name] = lb_result[:,k]\n",
    "#             print(name)\n",
    "\n",
    "        lb_result = lb.transform(df_x_test[feature].astype(\"str\"))\n",
    "        names = [f'{feature}_{l}' for l in lb.classes_]\n",
    "        for k, name in enumerate(names):\n",
    "            dfx_test_model[name] = lb_result[:,k]\n",
    "            \n",
    "    for feature in engineered_features:\n",
    "        dfx_train_model[feature] = df_x_train[feature].astype(int)\n",
    "        dfx_test_model[feature] = df_x_test[feature].astype(int)\n",
    "        \n",
    "    for feature in df_facility_columns:\n",
    "        dfx_train_model[feature] = df_x_train[feature].astype(int)\n",
    "        dfx_test_model[feature] = df_x_test[feature].astype(int)  \n",
    "\n",
    "    return dfx_train_model, dfx_test_model\n",
    "\n",
    "dfx_train_model, dfx_test_model = encode_features(df_x_train, df_x_test, target_features, engineered_features, df_facility_columns)\n",
    "print(len(dfx_train_model.columns))\n",
    "print(len(dfx_test_model.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasiffication Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier#GradientTreeBoosting\n",
    "\n",
    "classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from dataframes into numrical rrays\n",
    "x_train, y_train = dfx_train_model.values, df_y_train.values\n",
    "x_test, y_test = dfx_test_model.values, df_y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers:  LogisticRegression Has a training score of 56.99999999999999 % accuracy score\n",
      "Classifiers:  KNeighborsClassifier Has a training score of 52.0 % accuracy score\n",
      "Classifiers:  DecisionTreeClassifier Has a training score of 48.0 % accuracy score\n",
      "Classifiers:  AdaBoostClassifier Has a training score of 56.99999999999999 % accuracy score\n",
      "Classifiers:  RandomForestClassifier Has a training score of 53.0 % accuracy score\n",
      "Classifiers:  ExtraTreesClassifier Has a training score of 51.0 % accuracy score\n"
     ]
    }
   ],
   "source": [
    "# looping over the classifiers and getting the model scores\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(x_train, y_train)\n",
    "    training_score = cross_val_score(classifier, x_train, y_train, cv=10)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the scores above I have picked the three highest scores to further examine\n",
    "new_classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LogisticRegression  AdaBoostClassifier  ExtraTreesClassifier  true\n",
       "0                   0                   0                     0     0\n",
       "1                   2                   2                     2     2\n",
       "2                   2                   1                     2     2\n",
       "3                   0                   0                     1     0\n",
       "4                   1                   1                     1     2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visual examination of the predicted results for each classifiers comapared to the real values\n",
    "classifier_predictions = {}\n",
    "\n",
    "for name, clf in new_classifiers.items():\n",
    "    pred = cross_val_predict(clf, x_train, y_train, cv=10)\n",
    "    classifier_predictions[name] = pred\n",
    "    \n",
    "classifier_predictions[\"true\"] = y_train\n",
    "df_pred = pd.DataFrame(classifier_predictions)\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in new_classifiers:\n",
    "    new_classifiers[model].fit(x_train, y_train)\n",
    "\n",
    "for model in new_classifiers:\n",
    "    clf = new_classifiers[\"ExtraTreesClassifier\"]\n",
    "    importance = clf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "    indices = np.argsort(importance)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking\n",
      "\n",
      "Feature: SOURCE_OF_ADMISSION_6, Importance: 0.0038688260887348672\n",
      "Feature: SOURCE_OF_ADMISSION_8, Importance: 0.003684274305898153\n",
      "Feature: SOURCE_OF_ADMISSION_D, Importance: 0.0035293733690079407\n",
      "Feature: NON_TEXAS, Importance: 0.0031307187986432767\n",
      "Feature: FROM_TEXAS, Importance: 0.0031091129327367535\n",
      "Feature: PAT_STATE_TX, Importance: 0.003074277444898382\n",
      "Feature: PAT_STATE_XX, Importance: 0.0029428624401178984\n",
      "Feature: SOURCE_OF_ADMISSION_9, Importance: 0.0022711171983333476\n",
      "Feature: RACE_1, Importance: 0.0016596799878966855\n",
      "Feature: PAT_STATE_ZZ, Importance: 0.001579724345857235\n",
      "Feature: PAT_COUNTRY_US, Importance: 0.0014731819721763922\n",
      "Feature: PAT_COUNTRY_XX, Importance: 0.0012446524716550119\n",
      "Feature: FAC_OTHER_LTC_IND, Importance: 0.0009691704648162969\n",
      "Feature: PAT_COUNTRY_MX, Importance: 0.00039721890177046827\n"
     ]
    }
   ],
   "source": [
    "low_importance = []\n",
    "\n",
    "print(\"Feature Ranking\\n\")\n",
    "feature_names = [dfx_train_model.columns[indices[f]] for f in range(importance.shape[0])]\n",
    "for f in range(importance.shape[0]):\n",
    "    if importance[indices[f]] < 0.004:\n",
    "        low_importance.append(feature_names[f])\n",
    "        print(\"Feature: {0}, Importance: {1}\".format(feature_names[f], importance[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# drop unimportant feature\n",
    "dfx_train_model.drop(columns=low_importance, inplace=True)\n",
    "dfx_test_model.drop(columns=low_importance, inplace=True)\n",
    "df_y_train.drop(columns=low_importance, inplace=True)\n",
    "df_y_test.drop(columns=low_importance, inplace=True)\n",
    "\n",
    "print(len(dfx_train_model.columns))\n",
    "print(len(dfx_test_model.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from dataframes into numrical rrays\n",
    "x_train, y_train = dfx_train_model.values, df_y_train.values\n",
    "x_test, y_test = dfx_test_model.values, df_y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers:  LogisticRegression Has a training score of 56.99999999999999 % accuracy score\n",
      "Classifiers:  KNeighborsClassifier Has a training score of 52.0 % accuracy score\n",
      "Classifiers:  DecisionTreeClassifier Has a training score of 49.0 % accuracy score\n",
      "Classifiers:  AdaBoostClassifier Has a training score of 56.99999999999999 % accuracy score\n",
      "Classifiers:  RandomForestClassifier Has a training score of 53.0 % accuracy score\n",
      "Classifiers:  ExtraTreesClassifier Has a training score of 51.0 % accuracy score\n"
     ]
    }
   ],
   "source": [
    "# looping over the classifiers and getting the model scores\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(x_train, y_train)\n",
    "    training_score = cross_val_score(classifier, x_train, y_train, cv=10)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>long</th>\n",
       "      <th>medium</th>\n",
       "      <th>short</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>2745</td>\n",
       "      <td>2628</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>1129</td>\n",
       "      <td>6188</td>\n",
       "      <td>4184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>470</td>\n",
       "      <td>3744</td>\n",
       "      <td>8252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  long  medium  short\n",
       "True                          \n",
       "long       2745    2628    650\n",
       "medium     1129    6188   4184\n",
       "short       470    3744   8252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>long</th>\n",
       "      <th>medium</th>\n",
       "      <th>short</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>2809</td>\n",
       "      <td>2560</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>1227</td>\n",
       "      <td>6254</td>\n",
       "      <td>4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>541</td>\n",
       "      <td>3831</td>\n",
       "      <td>8094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  long  medium  short\n",
       "True                          \n",
       "long       2809    2560    654\n",
       "medium     1227    6254   4020\n",
       "short       541    3831   8094"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>long</th>\n",
       "      <th>medium</th>\n",
       "      <th>short</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>2975</td>\n",
       "      <td>2134</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>2036</td>\n",
       "      <td>5387</td>\n",
       "      <td>4078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>1042</td>\n",
       "      <td>4359</td>\n",
       "      <td>7065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  long  medium  short\n",
       "True                          \n",
       "long       2975    2134    914\n",
       "medium     2036    5387   4078\n",
       "short      1042    4359   7065"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in new_classifiers:\n",
    "    print(model)\n",
    "    display(pd.crosstab(df_pred.true.map(target_labels), df_pred[model].map(target_labels), rownames=['True'], colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_classifiers = {}\n",
    "\n",
    "param_space = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"solver\":[\"liblinear\"],\n",
    "        \"penalty\": ['l1', 'l2'],\n",
    "        \"C\": [0.01, 0.1, 10, 100, 1000]\n",
    "#         \"max_iter\": [100, 300, 500]\n",
    "    },\n",
    "    \"AdaBoostClassifier\": {\n",
    "        \"algorithm\": [\"SAMME\", \"SAMME.R\"],\n",
    "        \"n_estimators\": [10, 30, 50, 80]    \n",
    "    },\n",
    "#     \"RandomForestClassifier\": {\n",
    "#         \"min_samples_leaf\": range(3, 6),\n",
    "#         \"max_depth\": range(2,4), \n",
    "#         \"criterion\": [\"gini\", \"entropy\"]  \n",
    "#     },\n",
    "    \"ExtraTreesClassifier\": {\n",
    "        \"min_samples_leaf\": range(3, 6),\n",
    "        \"max_depth\": range(2,4), \n",
    "        \"criterion\": [\"gini\", \"entropy\"]\n",
    "    }\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Performing GridSearchCV on LogisticRegression...\n",
      "GridSearchCV(cv=5, error_score=nan,\n",
      "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                          fit_intercept=True,\n",
      "                                          intercept_scaling=1, l1_ratio=None,\n",
      "                                          max_iter=500, multi_class='auto',\n",
      "                                          n_jobs=None, penalty='l2',\n",
      "                                          random_state=None, solver='lbfgs',\n",
      "                                          tol=0.0001, verbose=0,\n",
      "                                          warm_start=False),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'C': [0.01, 0.1, 10, 100, 1000],\n",
      "                         'penalty': ['l1', 'l2'], 'solver': ['liblinear']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "LogisticRegression Cross Validation Score (recall_macro): 57.10%\n"
     ]
    }
   ],
   "source": [
    "name = \"LogisticRegression\"\n",
    "param = param_space[name]\n",
    "print(\"\\n\\nPerforming GridSearchCV on %s...\" % name)\n",
    "clf = GridSearchCV(classifiers[name], param, cv=5)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "best_classifiers[name] = clf\n",
    "\n",
    "score = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "print(best_classifiers[name])\n",
    "print(\"%s Cross Validation Score (%s): %.2f%%\" % (name, metric, 100*score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression -> {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best parameters for Logistic Regression -> {best_classifiers[name].best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Performing GridSearchCV on AdaBoostClassifier...\n",
      "GridSearchCV(cv=5, error_score=nan,\n",
      "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                                          base_estimator=None,\n",
      "                                          learning_rate=1.0, n_estimators=50,\n",
      "                                          random_state=None),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'algorithm': ['SAMME', 'SAMME.R'],\n",
      "                         'n_estimators': [10, 30, 50, 80]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "AdaBoostClassifier Cross Validation Score (recall_macro): 57.19%\n"
     ]
    }
   ],
   "source": [
    "name = \"AdaBoostClassifier\"\n",
    "param = param_space[name]\n",
    "print(\"\\n\\nPerforming GridSearchCV on %s...\" % name)\n",
    "clf = GridSearchCV(classifiers[name], param, cv=5)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "best_classifiers[name] = clf\n",
    "\n",
    "score = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "print(best_classifiers[name])\n",
    "print(\"%s Cross Validation Score (%s): %.2f%%\" % (name, metric, 100*score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Ada Boost Classifier -> {'algorithm': 'SAMME.R', 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best parameters for Ada Boost Classifier -> {best_classifiers[name].best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Performing GridSearchCV on ExtraTreesClassifier...\n",
      "GridSearchCV(cv=5, error_score=nan,\n",
      "             estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
      "                                            class_weight=None, criterion='gini',\n",
      "                                            max_depth=None, max_features='auto',\n",
      "                                            max_leaf_nodes=None,\n",
      "                                            max_samples=None,\n",
      "                                            min_impurity_decrease=0.0,\n",
      "                                            min_impurity_split=None,\n",
      "                                            min_samples_leaf=1,\n",
      "                                            min_samples_split=2,\n",
      "                                            min_weight_fraction_leaf=0.0,\n",
      "                                            n_estimators=100, n_jobs=None,\n",
      "                                            oob_score=False, random_state=None,\n",
      "                                            verbose=0, warm_start=False),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'criterion': ['gini', 'entropy'],\n",
      "                         'max_depth': range(2, 4),\n",
      "                         'min_samples_leaf': range(3, 6)},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "ExtraTreesClassifier Cross Validation Score (recall_macro): 54.64%\n"
     ]
    }
   ],
   "source": [
    "name = \"ExtraTreesClassifier\"\n",
    "param = param_space[name]\n",
    "print(\"\\n\\nPerforming GridSearchCV on %s...\" % name)\n",
    "clf = GridSearchCV(classifiers[name], param, cv=5)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "best_classifiers[name] = clf\n",
    "\n",
    "score = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "print(best_classifiers[name])\n",
    "print(\"%s Cross Validation Score (%s): %.2f%%\" % (name, metric, 100*score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Extra Trees Classifier -> {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best parameters for Extra Trees Classifier -> {best_classifiers[name].best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grading = pd.merge(df_grading_raw, df_facility, on=\"THCIC_ID\", how=\"left\")\n",
    "\n",
    "# replace empty values\n",
    "for i in range(2, len(df_facility.columns) - 1):\n",
    "    col = df_facility.columns[i]\n",
    "    df_grading[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE_OF_ADMISSION: -> ['2' '1' '3' '4' '5' '9']\n",
      "SOURCE_OF_ADMISSION: -> ['1' '2' '5' '6' 'D' '4' '8' '9' '0']\n",
      "PAT_STATE: -> ['TX' 'XX' 'ZZ']\n",
      "SEX_CODE: -> ['F' 'M' 'U']\n",
      "RACE: -> ['4' '5' '3' '2' '1']\n",
      "ETHNICITY: -> ['1' '2' '3']\n",
      "PAT_AGE: -> ['3' '4' '5' '1' '2']\n",
      "PAT_COUNTRY: -> ['US' 'MX' 'XX']\n",
      "POA_PROVIDER_INDICATOR: -> ['M' 'X' 'R']\n",
      "ILLNESS_SEVERITY: -> ['2' '1' '3' '4']\n",
      "RISK_MORTALITY: -> ['1' '2' '3' '4']\n"
     ]
    }
   ],
   "source": [
    "# Clean grading data\n",
    "ml.clean_data(df_grading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "feature_engineering(df_grading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split df_grading\n",
    "# df_x_train, df_x_test, df_y_train, df_y_test = split_train_test(df_grading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "# encode features\n",
    "dfx_train_model, dfx_test_model = encode_features(df_x_train, df_grading, target_features, engineered_features, df_facility_columns)\n",
    "print(len(dfx_train_model.columns))\n",
    "print(len(dfx_test_model.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final classifier\n",
    "final_clf = AdaBoostClassifier(algorithm='SAMME.R', n_estimators=80)\n",
    "\n",
    "# make our predictions\n",
    "df_grading['TARGET'] = final_clf.fit(dfx_train_model, df_y_train).predict(dfx_test_model)\n",
    "df_grading['TARGET'] = df_grading['TARGET'].map(target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our prediction\n",
    "df_grading.loc[:, [\"RECORD_ID\", \"TARGET\"]].to_csv(\"df_grading_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating archive: my_assignment.zip\n",
      "\t01-Import.ipynb - OK\n",
      "\t02-EDA.ipynb - OK\n",
      "\t03-Model.ipynb - OK\n",
      "\tmy_lib.py - OK\n",
      "\tdf_grading_pred.csv - OK\n"
     ]
    }
   ],
   "source": [
    "ml.make_assignment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!say \"That is now done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
