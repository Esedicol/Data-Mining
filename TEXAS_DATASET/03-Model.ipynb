{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import glob, os\n",
    "import my_lib as ml\n",
    "import json\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer, accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "SEED = 42\n",
    "target = \"TARGET\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORD_ID</th>\n",
       "      <th>DISCHARGE</th>\n",
       "      <th>THCIC_ID</th>\n",
       "      <th>PROVIDER_NAME</th>\n",
       "      <th>TYPE_OF_ADMISSION</th>\n",
       "      <th>SOURCE_OF_ADMISSION</th>\n",
       "      <th>PAT_STATE</th>\n",
       "      <th>PAT_COUNTRY</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>PUBLIC_HEALTH_REGION</th>\n",
       "      <th>PAT_STATUS</th>\n",
       "      <th>SEX_CODE</th>\n",
       "      <th>RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>ADMIT_WEEKDAY</th>\n",
       "      <th>LENGTH_OF_STAY</th>\n",
       "      <th>PAT_AGE</th>\n",
       "      <th>FIRST_PAYMENT_SRC</th>\n",
       "      <th>TYPE_OF_BILL</th>\n",
       "      <th>TOTAL_CHARGES</th>\n",
       "      <th>TOTAL_NON_COV_CHARGES</th>\n",
       "      <th>TOTAL_CHARGES_ACCOMM</th>\n",
       "      <th>TOTAL_NON_COV_CHARGES_ACCOMM</th>\n",
       "      <th>TOTAL_CHARGES_ANCIL</th>\n",
       "      <th>TOTAL_NON_COV_CHARGES_ANCIL</th>\n",
       "      <th>POA_PROVIDER_INDICATOR</th>\n",
       "      <th>ADMITTING_DIAGNOSIS</th>\n",
       "      <th>PRINC_DIAG_CODE</th>\n",
       "      <th>OTH_DIAG_CODE_1</th>\n",
       "      <th>MS_MDC</th>\n",
       "      <th>MS_DRG</th>\n",
       "      <th>MS_GROUPER_VERSION_NBR</th>\n",
       "      <th>MS_GROUPER_ERROR_CODE</th>\n",
       "      <th>APR_MDC</th>\n",
       "      <th>APR_DRG</th>\n",
       "      <th>RISK_MORTALITY</th>\n",
       "      <th>ILLNESS_SEVERITY</th>\n",
       "      <th>APR_GROUPER_VERSION_NBR</th>\n",
       "      <th>APR_GROUPER_ERROR_CODE</th>\n",
       "      <th>ATTENDING_PHYSICIAN_UNIF_ID</th>\n",
       "      <th>ENCOUNTER_INDICATOR</th>\n",
       "      <th>CERT_STATUS</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320136748870</td>\n",
       "      <td>2013Q3</td>\n",
       "      <td>838400</td>\n",
       "      <td>Memorial Hermann Rehab Hospital Katy</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>TX</td>\n",
       "      <td>US</td>\n",
       "      <td>201</td>\n",
       "      <td>06</td>\n",
       "      <td>07</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>MA</td>\n",
       "      <td>111</td>\n",
       "      <td>1671.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>526.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>X</td>\n",
       "      <td>V5789</td>\n",
       "      <td>V5789</td>\n",
       "      <td>1919</td>\n",
       "      <td>23</td>\n",
       "      <td>945</td>\n",
       "      <td>01300</td>\n",
       "      <td>00</td>\n",
       "      <td>23</td>\n",
       "      <td>860</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>07300</td>\n",
       "      <td>00</td>\n",
       "      <td>1229763162</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120130546450</td>\n",
       "      <td>2013Q1</td>\n",
       "      <td>409000</td>\n",
       "      <td>John Peter Smith Hospital</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>US</td>\n",
       "      <td>367</td>\n",
       "      <td>03</td>\n",
       "      <td>01</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>MA</td>\n",
       "      <td>111</td>\n",
       "      <td>53064.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4092.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48972.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M</td>\n",
       "      <td>78650</td>\n",
       "      <td>41401</td>\n",
       "      <td>42822</td>\n",
       "      <td>05</td>\n",
       "      <td>247</td>\n",
       "      <td>01300</td>\n",
       "      <td>00</td>\n",
       "      <td>05</td>\n",
       "      <td>175</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>07300</td>\n",
       "      <td>00</td>\n",
       "      <td>1578252829</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RECORD_ID DISCHARGE THCIC_ID                         PROVIDER_NAME  \\\n",
       "0  320136748870    2013Q3   838400  Memorial Hermann Rehab Hospital Katy   \n",
       "1  120130546450    2013Q1   409000             John Peter Smith Hospital   \n",
       "\n",
       "  TYPE_OF_ADMISSION SOURCE_OF_ADMISSION PAT_STATE PAT_COUNTRY COUNTY  \\\n",
       "0                 3                   4        TX          US    201   \n",
       "1                 1                   1        TX          US    367   \n",
       "\n",
       "  PUBLIC_HEALTH_REGION PAT_STATUS SEX_CODE RACE ETHNICITY ADMIT_WEEKDAY  \\\n",
       "0                   06         07        F    4         2             2   \n",
       "1                   03         01        M    5         1             2   \n",
       "\n",
       "  LENGTH_OF_STAY PAT_AGE FIRST_PAYMENT_SRC TYPE_OF_BILL TOTAL_CHARGES  \\\n",
       "0              1      20                MA          111       1671.00   \n",
       "1              2      13                MA          111      53064.01   \n",
       "\n",
       "  TOTAL_NON_COV_CHARGES TOTAL_CHARGES_ACCOMM TOTAL_NON_COV_CHARGES_ACCOMM  \\\n",
       "0                  0.00              1145.00                         0.00   \n",
       "1                  0.00              4092.00                         0.00   \n",
       "\n",
       "  TOTAL_CHARGES_ANCIL TOTAL_NON_COV_CHARGES_ANCIL POA_PROVIDER_INDICATOR  \\\n",
       "0              526.00                        0.00                      X   \n",
       "1            48972.01                        0.00                      M   \n",
       "\n",
       "  ADMITTING_DIAGNOSIS PRINC_DIAG_CODE OTH_DIAG_CODE_1 MS_MDC MS_DRG  \\\n",
       "0               V5789           V5789            1919     23    945   \n",
       "1               78650           41401           42822     05    247   \n",
       "\n",
       "  MS_GROUPER_VERSION_NBR MS_GROUPER_ERROR_CODE APR_MDC APR_DRG RISK_MORTALITY  \\\n",
       "0                  01300                    00      23     860              2   \n",
       "1                  01300                    00      05     175              2   \n",
       "\n",
       "  ILLNESS_SEVERITY APR_GROUPER_VERSION_NBR APR_GROUPER_ERROR_CODE  \\\n",
       "0                3                   07300                     00   \n",
       "1                2                   07300                     00   \n",
       "\n",
       "  ATTENDING_PHYSICIAN_UNIF_ID ENCOUNTER_INDICATOR CERT_STATUS TARGET  \n",
       "0                  1229763162                  01           1  short  \n",
       "1                  1578252829                  01           2  short  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(49984, 43)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"data/df_train_sample_00_of_20.csv\", dtype=str)\n",
    "df2 = pd.read_csv(f\"data/df_train_sample_00_of_20.csv\", dtype=str)\n",
    "display(df.head(2))\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'long', 1: 'medium', 2: 'short'}\n"
     ]
    }
   ],
   "source": [
    "if df['TARGET'].dtype!=int:\n",
    "    le_target = LabelEncoder()\n",
    "    df['TARGET']= le_target.fit_transform(df['TARGET'])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "target_labels = {c:le_target.inverse_transform([c])[0] for c in [0,1,2]}\n",
    "print(target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE_OF_ADMISSION: -> ['3' '1' '2' '4' '5' '9']\n",
      "SOURCE_OF_ADMISSION: -> ['4' '1' '2' '8' '5' '9' '6' 'D']\n",
      "PAT_STATE: -> ['TX' 'XX' 'ZZ']\n",
      "SEX_CODE: -> ['F' 'M' 'U']\n",
      "RACE: -> ['4' '5' '3' '2' '1']\n",
      "ETHNICITY: -> ['2' '1' '3']\n",
      "PAT_AGE: -> ['5' '4' '2' '3' '1']\n",
      "PAT_COUNTRY: -> ['US' 'MX' 'XX']\n"
     ]
    }
   ],
   "source": [
    "# open feature label file\n",
    "feature_labels = {}\n",
    "\n",
    "with open(\"data/feature_labels.json\") as f:\n",
    "  feature_labels = json.load(f)\n",
    "\n",
    "ml.clean_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset in Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(target, axis=1)\n",
    "y = df.TARGET\n",
    "\n",
    "df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(x,y, test_size = 0.4, stratify = y, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE_OF_ADMISSION_1\n",
      "SOURCE_OF_ADMISSION_2\n",
      "SOURCE_OF_ADMISSION_4\n",
      "SOURCE_OF_ADMISSION_5\n",
      "SOURCE_OF_ADMISSION_6\n",
      "SOURCE_OF_ADMISSION_8\n",
      "SOURCE_OF_ADMISSION_9\n",
      "SOURCE_OF_ADMISSION_D\n",
      "PAT_STATE_TX\n",
      "PAT_STATE_XX\n",
      "PAT_STATE_ZZ\n",
      "SEX_CODE_F\n",
      "SEX_CODE_M\n",
      "SEX_CODE_U\n",
      "RACE_1\n",
      "RACE_2\n",
      "RACE_3\n",
      "RACE_4\n",
      "RACE_5\n",
      "ETHNICITY_1\n",
      "ETHNICITY_2\n",
      "ETHNICITY_3\n",
      "ADMIT_WEEKDAY_1\n",
      "ADMIT_WEEKDAY_2\n",
      "ADMIT_WEEKDAY_3\n",
      "ADMIT_WEEKDAY_4\n",
      "ADMIT_WEEKDAY_5\n",
      "ADMIT_WEEKDAY_6\n",
      "ADMIT_WEEKDAY_7\n",
      "PAT_AGE_1\n",
      "PAT_AGE_2\n",
      "PAT_AGE_3\n",
      "PAT_AGE_4\n",
      "PAT_AGE_5\n",
      "PAT_COUNTRY_MX\n",
      "PAT_COUNTRY_US\n",
      "PAT_COUNTRY_XX\n"
     ]
    }
   ],
   "source": [
    "target_features = [ \"SOURCE_OF_ADMISSION\", \"PAT_STATE\", \"SEX_CODE\", \"RACE\", \"ETHNICITY\", \"ADMIT_WEEKDAY\", \"PAT_AGE\", \"PAT_COUNTRY\"]\n",
    "\n",
    "def encode_features(df_x_train, df_x_test, target_features, debug=False):\n",
    "    # create dataframes to populate\n",
    "    dfx_train_model = df_x_train.loc[:,[]]\n",
    "    dfx_test_model = df_x_test.loc[:,[]]\n",
    "\n",
    "    # encoding features using LabelBinarizer\n",
    "    for feature in target_features:\n",
    "\n",
    "        lb = LabelBinarizer()\n",
    "        lb_result = lb.fit_transform(df_x_train[feature].astype(\"str\"))\n",
    "        names = [f'{feature}_{l}' for l in lb.classes_]\n",
    "\n",
    "        for k, name in enumerate(names):\n",
    "            dfx_train_model[name] = lb_result[:,k]\n",
    "            print(name)\n",
    "\n",
    "        lb_result = lb.transform(df_x_test[feature].astype(\"str\"))\n",
    "        names = [f'{feature}_{l}' for l in lb.classes_]\n",
    "        for k, name in enumerate(names):\n",
    "            dfx_test_model[name] = lb_result[:,k]\n",
    "\n",
    "    return dfx_train_model, dfx_test_model\n",
    "\n",
    "dfx_train_model, dfx_test_model = encode_features(df_x_train, df_x_test, target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier#GradientTreeBoosting\n",
    "\n",
    "# Using a few classifiers with the dataset\n",
    "classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNearestNeighbors\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"ExtraTreeClassifier\": ExtraTreesClassifier(n_estimators=200)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = dfx_train_model.values, df_y_train.values\n",
    "x_test, y_test = dfx_test_model.values, df_y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_classifiers = {}\n",
    "\n",
    "param_space = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"solver\":[\"liblinear\", \"saga\"],\n",
    "        \"penalty\": ['l1', 'l2'], \n",
    "        \"C\": [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    },\n",
    "    \"KNearestNeighbors\": {\n",
    "        \"n_neighbors\": range(2, 5, 10), \n",
    "        \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"criterion\": [\"gini\", \"entropy\"], \n",
    "        \"max_depth\": range(2,8), \n",
    "        \"min_samples_leaf\": range(1,8)\n",
    "    },\n",
    "    \"AdaBoostClassifier\": {\n",
    "        \"algorithm\": [\"SAMME\", \"SAMME.R\"],\n",
    "        \"n_estimators\": [10, 30, 50, 80]    \n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"min_samples_leaf\": range(3, 6),\n",
    "        \"max_depth\": range(2,4), \n",
    "        \"criterion\": [\"gini\", \"entropy\"]  \n",
    "    },\n",
    "    \"ExtraTreeClassifier\": {\n",
    "        \"min_samples_leaf\": range(3, 6),\n",
    "        \"max_depth\": range(2,4), \n",
    "        \"criterion\": [\"gini\", \"entropy\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Performing GridSearchCV on LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# clf = ExtraTreesClassifier()\n",
    "# clf.get_params()\n",
    "\n",
    "for name in classifiers:\n",
    "    param = param_space[name]\n",
    "    print(\"\\n\\nPerforming GridSearchCV on %s...\" % name)\n",
    "    clf = GridSearchCV(classifiers[name], param, cv=5)\n",
    "    \n",
    "    clf.fit(x_train, y_train)\n",
    "    best_classifiers[name] = clf\n",
    "    \n",
    "    score = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "    print(best_classifiers[name])\n",
    "    print(\"%s Cross Validation Score (%s): %.2f%%\" % (name, metric, 100*score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!say \"Doneeee\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping over the classifiers and getting the model scores\n",
    "metric = \"recall_macro\"\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(x_train, y_train)\n",
    "    training_score = cross_val_score(classifier, x_train, y_train, cv=10)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_predictions = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    pred = cross_val_predict(clf, x_train, y_train, cv=10)\n",
    "    classifier_predictions[name] = pred\n",
    "    \n",
    "classifier_predictions[\"True\"] = y_train\n",
    "df_pred = pd.DataFrame(classifier_predictions)\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
