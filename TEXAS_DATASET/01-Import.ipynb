{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Texas Hospital Discharge - Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas_profiling\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "import glob, os\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for d in [\"src\", \"data\", \"doc\", \"output\"]:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading remote file my_lib.py\n",
      "Downloading remote file train.csv.gz\n",
      "Downloading remote file grading.csv.gz\n",
      "Downloading remote file Facility_type1q2013_tab.zip\n",
      "Downloading remote file Facility_type2q2013_tab.zip\n",
      "Downloading remote file Facility_type3q2013_tab.zip\n",
      "Downloading remote file Facility_type4q2013_tab.zip\n",
      "Downloading remote file UserManual1Q2013.pdf\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://kmurphy.bitbucket.io/modules/Data_Mining_2/topics/05-Assignment/01-Specification/files/\"\n",
    "\n",
    "files = \"my_lib.py train.csv.gz grading.csv.gz Facility_type1q2013_tab.zip Facility_type2q2013_tab.zip Facility_type3q2013_tab.zip Facility_type4q2013_tab.zip UserManual1Q2013.pdf\"\n",
    "\n",
    "for filename in files.split(\" \"):\n",
    "    \n",
    "    ext = filename.split(\".\")[-1]\n",
    "    dest = {\"pdf\":\"doc\", \"py\":\".\", \"ipynb\":\".\", \"gz\":\"src\", \"zip\":\"src\"}[ext]\n",
    "   \n",
    "    source = f\"{URL}/{filename}\"\n",
    "    target = f\"{dest}/{filename}\"\n",
    "\n",
    "    if not os.path.isfile(target):\n",
    "        print (f\"Downloading remote file {filename}\", sep=\"\")\n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(source, target)\n",
    "    else:\n",
    "        print(f\"Using local copy of {filename} in folder {dest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 194)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"src/train.csv.gz\", dtype=str)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Columns if half of its rows is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code below prints a list of all the columns containing a null value\n",
    "null_list = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "# how much of our data is missing?\n",
    "isnull_count = df.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 194)\n"
     ]
    }
   ],
   "source": [
    "# Dropping irrelevant columns to reduce size of dataset\n",
    "nl = []\n",
    "for i in df.columns:\n",
    "    if df[i].isnull().sum() >= 50000:\n",
    "        nl.append(i)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 153 columns..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000000, 41)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dropping irrelevant columns \n",
    "print(f'Dropping {len(nl)} columns..')\n",
    "df = df.drop(columns=nl)   \n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Construct Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"LENGTH_OF_STAY\"], inplace=True)\n",
    "df.LENGTH_OF_STAY = df.LENGTH_OF_STAY.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "short     414152\n",
       "medium    381437\n",
       "long      204109\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"TARGET\"] = df.LENGTH_OF_STAY.apply(lambda x: \"short\" if x<3 else (\"medium\" if x<=6 else \"long\"))\n",
    "df.TARGET.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999698, 42)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle or randomize the dataframe\n",
    "df_sample = df.sample(frac=1, random_state=SEED)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split 1M rows in out data into 20 smaller csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/df_train_sample_00_of_20.csv\n",
      "data/df_train_sample_01_of_20.csv\n",
      "data/df_train_sample_02_of_20.csv\n",
      "data/df_train_sample_03_of_20.csv\n",
      "data/df_train_sample_04_of_20.csv\n",
      "data/df_train_sample_05_of_20.csv\n",
      "data/df_train_sample_06_of_20.csv\n",
      "data/df_train_sample_07_of_20.csv\n",
      "data/df_train_sample_08_of_20.csv\n",
      "data/df_train_sample_09_of_20.csv\n",
      "data/df_train_sample_10_of_20.csv\n",
      "data/df_train_sample_11_of_20.csv\n",
      "data/df_train_sample_12_of_20.csv\n",
      "data/df_train_sample_13_of_20.csv\n",
      "data/df_train_sample_14_of_20.csv\n",
      "data/df_train_sample_15_of_20.csv\n",
      "data/df_train_sample_16_of_20.csv\n",
      "data/df_train_sample_17_of_20.csv\n",
      "data/df_train_sample_18_of_20.csv\n",
      "data/df_train_sample_19_of_20.csv\n"
     ]
    }
   ],
   "source": [
    "parts = 20\n",
    "nrows = df.shape[0] // parts\n",
    "for k in range(parts):\n",
    "    filename = ('data/df_train_sample_%02d_of_%d.csv' % (k, parts))\n",
    "    print(filename)\n",
    "    df_sample.iloc[k*nrows:(k+1)*nrows].to_csv(filename, index=False)\n",
    "\n",
    "# for parts in [40,20,10,5,2,1]:\n",
    "#     nrows = df.shape[0] // parts\n",
    "#     filename = ('data/df_train_sample_%02d_of_%d.csv' % (k, parts))\n",
    "#     print(filename)\n",
    "#     df_sample.iloc[k*nrows:(k+1)*nrows].to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grading = pd.read_csv(f\"src/grading.csv.gz\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grading.to_csv(\"data/grading.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
