{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics, svm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {
    "iris.png": {
     "image/png": "https://github.com/Esedicol/Data-Mining/blob/master/Classification/iris.png"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Import\tthe\tIris Dataset from\tSciKitLearn.\n",
    "![iris.png](attachment:iris.png)\n",
    "The iris data set has a total of: \n",
    "- 3 classes\n",
    "- 50 samples per classes\n",
    "- 150 total samples\n",
    "- has a fimension of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "5                5.4               3.9                1.7               0.4   \n",
       "\n",
       "   class  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "5    0.0  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "# Import iris data set into a dataframe \n",
    "# Also add a class column to when we split the data into later in qs 2\n",
    "df = pd.DataFrame(np.c_[iris['data'], iris['target']],columns=iris['feature_names'] + ['class'])\n",
    "\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Split\t information\t from\t the\t dataset\t into Train, Test,\n",
    "Validation\tsubset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the object column into three classes (50, 5) \n",
    "c1 = df[df['class'] == 0]\n",
    "c2 = df[df['class'] == 1]\n",
    "c3 = df[df['class'] == 2]\n",
    "\n",
    "# Add 'class' to column features\n",
    "col = iris.feature_names.append('class')\n",
    "\n",
    "# create new empty data frames for Train, Test and Validation subset\n",
    "train = pd.DataFrame(columns=col)\n",
    "test = pd.DataFrame(columns=col)\n",
    "validation = pd.DataFrame(columns=col)\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of the data\n",
    "irisSubsets = []\n",
    "\n",
    "# Spliting iris data set into three (train, test and validation) with equal number or outcomes\n",
    "for data in [c1, c2, c3]:\n",
    "    X = data.drop(['class'], axis=1)\n",
    "    y = data['class']\n",
    "        \n",
    "    # Since we have to split iris into 3, we have to split as follows (train, (test + validation)) and then split \n",
    "    # (test + validation)\n",
    "    \n",
    "    # Split one\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\n",
    "    # Split two (test + validation)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1)\n",
    "        \n",
    "    # Add the splitted data into the correspoding classes and we ignore the index because it is not needed\n",
    "    train = pd.concat([train, pd.concat([X_train, y_train], axis=1)], ignore_index=True)\n",
    "    test = pd.concat([test, pd.concat([X_test, y_test], axis=1)], ignore_index=True) \n",
    "    validation = pd.concat([validation, pd.concat([X_val, y_val], axis=1)], ignore_index=True) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Ensure\tthe\tsubsets\tare\t Independent\tand\tRepresentative\t\n",
    "of\tthe\toriginal\tdataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sunsets of iris\n",
    "X_train = train.drop(['class'], axis=1).values\n",
    "y_train = train['class'].values\n",
    "\n",
    "X_test = test.drop(['class'], axis=1).values\n",
    "y_test = test['class'].values\n",
    "\n",
    "X_val = validation.drop(['class'], axis=1).values\n",
    "y_val = validation['class'].values\n",
    "\n",
    "# storing the subset in a list\n",
    "irisSubsets = [X_train, y_train, X_test, y_test, X_val, y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows:  150\n"
     ]
    }
   ],
   "source": [
    "# test that sum of number of values in all three adds up to 150\n",
    "\n",
    "# Train 50% of data\n",
    "n1 = train.shape[0]\n",
    "\n",
    "# Test 25% of data\n",
    "n2 = test.shape[0]\n",
    "\n",
    "# Validation 25% of data\n",
    "n3 = validation.shape[0]\n",
    "\n",
    "totalRows = n1 + n2 + n3\n",
    "print('Total number of rows: ', totalRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Build\tthe\tfirst\tclassifier\tfor\tthe\tproblem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to get accuracy of the model\n",
    "def get_accuracy(y_pred):\n",
    "    chi = stats.chi2_contingency(pd.crosstab(index=y_val, columns=y_pred))\n",
    "    effect = np.sqrt(chi[0]/(len(y_val)*2))\n",
    "\n",
    "    return effect, metrics.accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared Effect: 0.9309493362512629\n",
      "Sklearn Accuracy: 0.9487179487179487\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "# We will create an SVM Classifier\n",
    "classifier1 = SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "# clf.fit(X, y)  \n",
    "classifier1.fit(irisSubsets[0], irisSubsets[1])\n",
    "\n",
    "# Get prediction clf.predict\n",
    "y_pred = classifier1.predict(irisSubsets[4]) \n",
    "\n",
    "clf_1 = get_accuracy(y_pred)\n",
    "print(\"Chi-squared Effect:\", clf_1[0])\n",
    "print(\"Sklearn Accuracy:\", clf_1[1])\n",
    "\n",
    "ac1 = clf_1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "Build\tthe\tsecond\tclassifier\tfor\tthe\tproblem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared Effect: 0.9013878188659973\n",
      "Sklearn Accuracy: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "# Build the second clasifier using decision tree\n",
    "classifier2 = DecisionTreeClassifier(random_state=0)  \n",
    "\n",
    "# clf.fit(X, y)  \n",
    "classifier2.fit(irisSubsets[0], irisSubsets[1])\n",
    "\n",
    "# Get prediction clf.predict\n",
    "y_pred = classifier2.predict(irisSubsets[4]) \n",
    "\n",
    "clf_2 = get_accuracy(y_pred)\n",
    "print(\"Chi-squared Effect:\", clf_2[0])\n",
    "print(\"Sklearn Accuracy:\", clf_2[1])\n",
    "\n",
    "ac2 = clf_2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "Build\tthe\tthird\tand\tfinal\tclassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Accuracy: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "# Build the final clasifier using logistic regression\n",
    "classifier3 = GaussianNB()\n",
    "\n",
    "# clf.fit(X, y)  \n",
    "classifier3.fit(irisSubsets[0], irisSubsets[1])\n",
    "\n",
    "# Get prediction clf.predict\n",
    "y_pred = classifier3.predict(irisSubsets[2]) \n",
    "\n",
    "ac3 = accuracy_score(irisSubsets[3], y_pred)\n",
    "print(\"Sklearn Accuracy:\", ac3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "Select\tthe\tbest\tout\tof\tthe\tthree\tclassifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 1:  0.9487179487179487\n",
      "Classifier 2:  0.9230769230769231\n",
      "Classifier 3:  0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "# To find out which is the best classifier we basically compary each accuracy and select the one closest to 1\n",
    "print(\"Classifier 1: \", ac1)\n",
    "print(\"Classifier 2: \", ac2)\n",
    "print(\"Classifier 3: \", ac3)\n",
    "\n",
    "# Based on the result below GaussianNB gives the best result for accuracy.\n",
    "# GaussianNB is the best out of the three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "Report\t on\t the\t future\t performance\t of\t the\t selected\t\n",
    "classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show the report for each classifier\n",
    "def report(classifier): \n",
    "    prediction_valid = classifier.predict(irisSubsets[4])\n",
    "    print(classification_report(irisSubsets[5], prediction_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 1: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        13\n",
      "         1.0       0.87      1.00      0.93        13\n",
      "         2.0       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.95        39\n",
      "   macro avg       0.96      0.95      0.95        39\n",
      "weighted avg       0.96      0.95      0.95        39\n",
      "\n",
      "Classifier 2: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        13\n",
      "         1.0       0.81      1.00      0.90        13\n",
      "         2.0       1.00      0.77      0.87        13\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.94      0.92      0.92        39\n",
      "weighted avg       0.94      0.92      0.92        39\n",
      "\n",
      "Classifier 3: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        13\n",
      "         1.0       0.93      1.00      0.96        13\n",
      "         2.0       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.97        39\n",
      "   macro avg       0.98      0.97      0.97        39\n",
      "weighted avg       0.98      0.97      0.97        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display all reports on all three classifier\n",
    "print(\"Classifier 1: \")\n",
    "report(classifier1)\n",
    "\n",
    "print(\"Classifier 2: \")\n",
    "report(classifier2)\n",
    "\n",
    "print(\"Classifier 3: \")\n",
    "report(classifier3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
